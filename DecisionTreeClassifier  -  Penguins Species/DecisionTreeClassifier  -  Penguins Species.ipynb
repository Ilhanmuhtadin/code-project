{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "def input_mlflow(cv_r_v,increment_number,X_train, y_train,pipeline,run_name,experiment_id,X_test,y_test):\n",
    "    \n",
    "\n",
    "    for wi in range(len(cv_r_v)):\n",
    "        \n",
    "        #====================skema===================\n",
    "        cols_spec = []\n",
    "        data_map = {\n",
    "                'int64': 'integer',\n",
    "                'float64': 'double',\n",
    "                'bool': 'boolean',\n",
    "                'str': 'string',\n",
    "                'object': 'string',\n",
    "                \"date\": 'datetime'\n",
    "            }\n",
    "\n",
    "        for name, dtype in X_train.dtypes.to_dict().items():\n",
    "            cols_spec.append(ColSpec(name=name, type=data_map[str(dtype)]))\n",
    "        input_schema = Schema(inputs=cols_spec)\n",
    "        output_schema = Schema([ColSpec(name=\"label\", type=\"string\")])\n",
    "        #parameter = ParamSpec(name=\"model_name\", dtype=\"string\", default=\"model1\")\n",
    "        #param_schema = ParamSchema(params=[parameter])\n",
    "        model_signature = ModelSignature(inputs=input_schema, outputs=output_schema)#, params=param_schema)\n",
    "        #print(\"MODEL SIGNATURE\")\n",
    "        #print(model_signature.to_dict())\n",
    "\n",
    "        model_signature = infer_signature(X_train, y_train)#, params={\"model_name\": \"model1\"})\n",
    "        #print(\"MODEL SIGNATURE\")\n",
    "        #print(model_signature.to_dict())\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #====================buat run baru===================\n",
    "        run_name_with_increment = f\"{run_name}__{increment_number}\"\n",
    "            # Membuka run MLflow\n",
    "        with mlflow.start_run(run_name=run_name_with_increment, experiment_id=experiment_id) as run:\n",
    "            # Mendapatkan run_id\n",
    "            run_id = mlflow.active_run().info.run_id\n",
    "        increment_number=increment_number+1\n",
    "        print(f\"{increment_number-1} -->   run_id:\", run_id)\n",
    "\n",
    "        \n",
    "        \n",
    "        #====================buat parameter model dan metric===================\n",
    "\n",
    "        # Definisikan grid parameter untuk dicari\n",
    "        param_grid = cv_r_v[wi]\n",
    "        \n",
    "        #====================model===================\n",
    "\n",
    "        # Inisialisasi GridSearchCV\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5,  scoring='accuracy')\n",
    "\n",
    "        # Lakukan pencarian grid\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "            \n",
    "        #====================parameter===================\n",
    "        pipe=grid_search.best_estimator_\n",
    "        \n",
    "        \n",
    "        first_step_name = list(pipe.named_steps.keys())[0:len(pipe)]\n",
    "        \n",
    "\n",
    "        for i in range(len(pipe)):\n",
    "            # Mendapatkan parameter dari langkah 'sca'\n",
    "            nama=first_step_name[i]\n",
    "            sca_params = pipe.get_params()[nama]\n",
    "\n",
    "                # Membuka run MLflow\n",
    "            with mlflow.start_run( experiment_id=experiment_id,run_id=run_id) as run:\n",
    "\n",
    "                # Log parameter secara otomatis menggunakan loop\n",
    "                for param_name, param_value in sca_params.get_params().items():\n",
    "                    param_name=nama+'__'+param_name\n",
    "                    #print(param_name,param_value)\n",
    "                    mlflow.log_param(param_name, param_value)\n",
    "                    \n",
    "                    \n",
    "                #====================metric===================\n",
    "                #matric\n",
    "                hasil_test=grid_search.predict(X_test)\n",
    " \n",
    "                \n",
    "                \n",
    "                \n",
    "                                # Menghitung akurasi\n",
    "                accuracy = accuracy_score(y_test, hasil_test)\n",
    "\n",
    "                # Menghitung F1 score\n",
    "                f1 = f1_score(y_test, hasil_test,average='macro')\n",
    "\n",
    "                # Menghitung recall\n",
    "                recall = recall_score(y_test, hasil_test,average='macro')\n",
    "\n",
    "                \n",
    "                \n",
    "                                # Menghitung precision\n",
    "                precision = precision_score(y_test, hasil_test,average='macro')\n",
    "\n",
    "\n",
    "   \n",
    "                \n",
    "\n",
    "                # log model \n",
    "                mlflow.sklearn.log_model(sk_model=grid_search, artifact_path=\"grid_search__\"+str(increment_number-1),signature=model_signature)\n",
    "\n",
    "                metrics = {\n",
    "                    'mean_test_score':pd.DataFrame(grid_search.cv_results_)['mean_test_score'].values[0],\n",
    "                    \"accuracy\": accuracy,\n",
    "                    \"f1\": f1,\n",
    "                    \"recall\": recall,\n",
    "                    \"precision\": precision,\n",
    "         \n",
    "                }\n",
    "\n",
    "                mlflow.log_metrics(metrics)\n",
    "                \n",
    "                \n",
    "        mlflow.end_run()\n",
    "    print('selesai')\n",
    "\n",
    "        \n",
    "    return increment_number\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "def ambil_best(grid_search,n):\n",
    "    cv_r=grid_search.copy()\n",
    "    cv_r_v=cv_r.sort_values(['rank_test_score'])\n",
    "    cv_r_v=cv_r_v.head(n)['params'].values\n",
    "\n",
    "    for wi in range(len(cv_r_v)):\n",
    "\n",
    "        for i in list(cv_r_v[wi]):\n",
    "\n",
    "            cv_r_v[wi][i]=[cv_r_v[wi][i]]\n",
    "\n",
    "\n",
    "    return cv_r_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def test(model_paths,X_test2,y_test):\n",
    "    ii=1\n",
    "    for i, model_path in enumerate(model_paths, start=1):\n",
    "        print(f'\\n\\n================================| model {ii} |==========================================')\n",
    "        \n",
    "        model = mlflow.sklearn.load_model(model_path)\n",
    "        y_pred = model.predict(X_test2)\n",
    "        print(f\"Classification Report for model {model_path[-2:]}:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(f\"Confusion Matrix for model {model_path[-2:]}:\\n\", confusion_matrix(y_test, y_pred), '\\n\\n')\n",
    "        \n",
    "        ii=ii+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import shapiro,normaltest,kstest,jarque_bera\n",
    "import pingouin as pg\n",
    "from pingouin import kruskal\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "\n",
    "\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.types.schema import Schema\n",
    "from mlflow.types.schema import ParamSchema\n",
    "from mlflow.types.schema import ParamSpec\n",
    "from mlflow.types.schema import ColSpec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_selector as selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency, fisher_exact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data_csv/data_bersih.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.10</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.50</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>44.45</td>\n",
       "      <td>17.3</td>\n",
       "      <td>197.0</td>\n",
       "      <td>4050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.70</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen             39.10             18.7              181.0   \n",
       "1  Adelie  Torgersen             39.50             17.4              186.0   \n",
       "2  Adelie  Torgersen             40.30             18.0              195.0   \n",
       "3  Adelie  Torgersen             44.45             17.3              197.0   \n",
       "4  Adelie  Torgersen             36.70             19.3              193.0   \n",
       "\n",
       "   body_mass_g  \n",
       "0       3750.0  \n",
       "1       3800.0  \n",
       "2       3250.0  \n",
       "3       4050.0  \n",
       "4       3450.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species              0\n",
       "island               0\n",
       "culmen_length_mm     0\n",
       "culmen_depth_mm      0\n",
       "flipper_length_mm    0\n",
       "body_mass_g          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 343 entries, 0 to 342\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            343 non-null    object \n",
      " 1   island             343 non-null    object \n",
      " 2   culmen_length_mm   343 non-null    float64\n",
      " 3   culmen_depth_mm    343 non-null    float64\n",
      " 4   flipper_length_mm  343 non-null    float64\n",
      " 5   body_mass_g        343 non-null    float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 16.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['species'])\n",
    "y=df['species']\n",
    "\n",
    "Xs=pd.get_dummies(X,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xs,y, test_size=0.15, random_state=142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=101)\n",
    "model.fit(X_train,y_train)\n",
    "model.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Dream</td>\n",
       "      <td>51.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>203.0</td>\n",
       "      <td>4100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>220.0</td>\n",
       "      <td>5150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Biscoe</td>\n",
       "      <td>37.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Dream</td>\n",
       "      <td>37.8</td>\n",
       "      <td>18.1</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Biscoe</td>\n",
       "      <td>34.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>187.0</td>\n",
       "      <td>2900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  body_mass_g\n",
       "185   Dream              51.0             18.8              203.0       4100.0\n",
       "254  Biscoe              49.1             14.8              220.0       5150.0\n",
       "62   Biscoe              37.6             17.0              185.0       3600.0\n",
       "149   Dream              37.8             18.1              193.0       3750.0\n",
       "54   Biscoe              34.5             18.1              187.0       2900.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=142)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "numeric_features = selector(dtype_include='float64')\n",
    "categorical_features = selector(dtype_include='object')\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='error'))\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('dt', DecisionTreeClassifier(random_state=101))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make param_grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x0000015F1B5AC940>),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('onehot',\n",
       "                                                                                          OneHotEncoder(drop='first'))]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_select...1B5AC8E0>)])),\n",
       "                                       ('dt',\n",
       "                                        DecisionTreeClassifier(random_state=101))]),\n",
       "             param_grid={'dt__criterion': ['gini', 'entropy'],\n",
       "                         'dt__max_depth': [2, 3, 4, 5, 6],\n",
       "                         'dt__max_features': [None, 'auto', 'sqrt', 'log2'],\n",
       "                         'dt__max_leaf_nodes': [None, 10, 20, 30],\n",
       "                         'dt__min_impurity_decrease': [0.0, 0.01, 0.1],\n",
       "                         'dt__min_samples_leaf': [1, 2, 4],\n",
       "                         'dt__min_samples_split': [2, 5, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'dt__max_depth': list(range(2, 7)),\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__min_samples_split': [2, 5, 10],\n",
    "    'dt__min_samples_leaf': [1, 2, 4],\n",
    "    'dt__max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "    'dt__max_leaf_nodes': [None, 10, 20, 30],\n",
    "    'dt__min_impurity_decrease': [0.0, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "grid_search_dt = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_dt__criterion</th>\n",
       "      <th>param_dt__max_depth</th>\n",
       "      <th>param_dt__max_features</th>\n",
       "      <th>param_dt__max_leaf_nodes</th>\n",
       "      <th>param_dt__min_impurity_decrease</th>\n",
       "      <th>param_dt__min_samples_leaf</th>\n",
       "      <th>param_dt__min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 6, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.967205</td>\n",
       "      <td>0.026685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0.012572</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.006431</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 4, ...</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.967138</td>\n",
       "      <td>0.017844</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>0.013611</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 5, ...</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.963569</td>\n",
       "      <td>0.022945</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.009309</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 3, ...</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.963502</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.011498</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 4, ...</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.963502</td>\n",
       "      <td>0.016265</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1838       0.007363      0.009187         0.006250        0.007654   \n",
       "865        0.012572      0.006287         0.006431        0.007877   \n",
       "1407       0.013611      0.007138         0.003125        0.006251   \n",
       "432        0.009447      0.007715         0.009309        0.007602   \n",
       "864        0.011498      0.006078         0.004238        0.006089   \n",
       "\n",
       "     param_dt__criterion param_dt__max_depth param_dt__max_features  \\\n",
       "1838                gini                   6                   auto   \n",
       "865                 gini                   4                   None   \n",
       "1407                gini                   5                   auto   \n",
       "432                 gini                   3                   None   \n",
       "864                 gini                   4                   None   \n",
       "\n",
       "     param_dt__max_leaf_nodes param_dt__min_impurity_decrease  \\\n",
       "1838                     None                             0.0   \n",
       "865                      None                             0.0   \n",
       "1407                     None                             0.0   \n",
       "432                      None                             0.0   \n",
       "864                      None                             0.0   \n",
       "\n",
       "     param_dt__min_samples_leaf param_dt__min_samples_split  \\\n",
       "1838                          1                          10   \n",
       "865                           1                           5   \n",
       "1407                          2                           2   \n",
       "432                           1                           2   \n",
       "864                           1                           2   \n",
       "\n",
       "                                                 params  split0_test_score  \\\n",
       "1838  {'dt__criterion': 'gini', 'dt__max_depth': 6, ...           1.000000   \n",
       "865   {'dt__criterion': 'gini', 'dt__max_depth': 4, ...           0.963636   \n",
       "1407  {'dt__criterion': 'gini', 'dt__max_depth': 5, ...           0.981818   \n",
       "432   {'dt__criterion': 'gini', 'dt__max_depth': 3, ...           0.963636   \n",
       "864   {'dt__criterion': 'gini', 'dt__max_depth': 4, ...           0.945455   \n",
       "\n",
       "      split1_test_score  split2_test_score  split3_test_score  \\\n",
       "1838           0.945455           0.927273           0.981818   \n",
       "865            1.000000           0.945455           0.963636   \n",
       "1407           0.945455           0.927273           0.981818   \n",
       "432            0.981818           0.945455           0.963636   \n",
       "864            0.981818           0.945455           0.981818   \n",
       "\n",
       "      split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "1838           0.981481         0.967205        0.026685                1  \n",
       "865            0.962963         0.967138        0.017844              136  \n",
       "1407           0.981481         0.963569        0.022945              281  \n",
       "432            0.962963         0.963502        0.011502              314  \n",
       "864            0.962963         0.963502        0.016265              314  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.DataFrame(grid_search_dt.cv_results_)\n",
    "df_1.drop_duplicates(subset=['mean_test_score', 'std_test_score', 'rank_test_score'], inplace=True)\n",
    "df_1 = df_1.sort_values(by=['mean_test_score', 'std_test_score'], ascending=[False, True])\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_ambil=ambil_best(df_1,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'dt__criterion': ['gini'], 'dt__max_depth': [6], 'dt__max_features': ['auto'], 'dt__max_leaf_nodes': [None], 'dt__min_impurity_decrease': [0.0], 'dt__min_samples_leaf': [1], 'dt__min_samples_split': [10]},\n",
       "       {'dt__criterion': ['gini'], 'dt__max_depth': [4], 'dt__max_features': [None], 'dt__max_leaf_nodes': [None], 'dt__min_impurity_decrease': [0.0], 'dt__min_samples_leaf': [1], 'dt__min_samples_split': [5]},\n",
       "       {'dt__criterion': ['gini'], 'dt__max_depth': [5], 'dt__max_features': ['auto'], 'dt__max_leaf_nodes': [None], 'dt__min_impurity_decrease': [0.0], 'dt__min_samples_leaf': [2], 'dt__min_samples_split': [2]},\n",
       "       {'dt__criterion': ['gini'], 'dt__max_depth': [3], 'dt__max_features': [None], 'dt__max_leaf_nodes': [None], 'dt__min_impurity_decrease': [0.0], 'dt__min_samples_leaf': [1], 'dt__min_samples_split': [2]},\n",
       "       {'dt__criterion': ['gini'], 'dt__max_depth': [4], 'dt__max_features': [None], 'dt__max_leaf_nodes': [None], 'dt__min_impurity_decrease': [0.0], 'dt__min_samples_leaf': [1], 'dt__min_samples_split': [2]},\n",
       "       {'dt__criterion': ['entropy'], 'dt__max_depth': [4], 'dt__max_features': [None], 'dt__max_leaf_nodes': [10], 'dt__min_impurity_decrease': [0.0], 'dt__min_samples_leaf': [4], 'dt__min_samples_split': [2]},\n",
       "       {'dt__criterion': ['gini'], 'dt__max_depth': [5], 'dt__max_features': ['auto'], 'dt__max_leaf_nodes': [None], 'dt__min_impurity_decrease': [0.0], 'dt__min_samples_leaf': [1], 'dt__min_samples_split': [2]},\n",
       "       {'dt__criterion': ['entropy'], 'dt__max_depth': [4], 'dt__max_features': [None], 'dt__max_leaf_nodes': [10], 'dt__min_impurity_decrease': [0.0], 'dt__min_samples_leaf': [1], 'dt__min_samples_split': [2]},\n",
       "       {'dt__criterion': ['gini'], 'dt__max_depth': [4], 'dt__max_features': [None], 'dt__max_leaf_nodes': [None], 'dt__min_impurity_decrease': [0.0], 'dt__min_samples_leaf': [4], 'dt__min_samples_split': [2]},\n",
       "       {'dt__criterion': ['entropy'], 'dt__max_depth': [4], 'dt__max_features': [None], 'dt__max_leaf_nodes': [10], 'dt__min_impurity_decrease': [0.0], 'dt__min_samples_leaf': [4], 'dt__min_samples_split': [10]}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ambil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341394191058264205\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    experiment_id = mlflow.create_experiment(\n",
    "        name=\"project_DecisionTreeClassifier_new\",\n",
    "        tags={\"env\": \"dev\", \"version\": \"1.0.0\"},\n",
    "    )\n",
    "\n",
    "    print(experiment_id)\n",
    "    \n",
    "\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"log___\"\n",
    "increment_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -->   run_id: 33b84a605b644b6f99b5f5d2977cd330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -->   run_id: 92c1ae0a01a6453bbf5a828c43b3de3d\n",
      "3 -->   run_id: dfd8370927da40b68ef30b34e47693ff\n",
      "4 -->   run_id: 1f91fb972a5e452b917a1c5e89d92bee\n",
      "5 -->   run_id: 4b14ccce89d9481586ae1856a56a5e66\n",
      "6 -->   run_id: 8ac4507b4af643e89d6ca130c4b92aac\n",
      "7 -->   run_id: 7cde4294dca34aa39e9b4433d8199e80\n",
      "8 -->   run_id: 66d91969c61745d682ae05c7bbc8f7fc\n",
      "9 -->   run_id: 4c939d269ee940b9af23c5f88e48aeeb\n",
      "10 -->   run_id: 394c35f6f9d34574a651a06561209efb\n",
      "selesai\n"
     ]
    }
   ],
   "source": [
    "\n",
    "increment_number=input_mlflow(data_ambil,increment_number,X_train, y_train,pipeline,run_name,experiment_id,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================| model 1 |==========================================\n",
      "Classification Report for model _1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       0.97      0.97      0.97        32\n",
      "   Chinstrap       0.93      1.00      0.96        13\n",
      "      Gentoo       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           0.97        69\n",
      "   macro avg       0.97      0.98      0.97        69\n",
      "weighted avg       0.97      0.97      0.97        69\n",
      "\n",
      "Confusion Matrix for model _1:\n",
      " [[31  1  0]\n",
      " [ 0 13  0]\n",
      " [ 1  0 23]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================| model 2 |==========================================\n",
      "Classification Report for model _3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       0.97      0.97      0.97        32\n",
      "   Chinstrap       0.93      1.00      0.96        13\n",
      "      Gentoo       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           0.97        69\n",
      "   macro avg       0.97      0.98      0.97        69\n",
      "weighted avg       0.97      0.97      0.97        69\n",
      "\n",
      "Confusion Matrix for model _3:\n",
      " [[31  1  0]\n",
      " [ 0 13  0]\n",
      " [ 1  0 23]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================| model 3 |==========================================\n",
      "Classification Report for model _5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       0.94      0.97      0.95        32\n",
      "   Chinstrap       0.93      1.00      0.96        13\n",
      "      Gentoo       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.96        69\n",
      "   macro avg       0.96      0.96      0.96        69\n",
      "weighted avg       0.96      0.96      0.96        69\n",
      "\n",
      "Confusion Matrix for model _5:\n",
      " [[31  1  0]\n",
      " [ 0 13  0]\n",
      " [ 2  0 22]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_paths = [\n",
    "  \n",
    "    'mlruns/341394191058264205/33b84a605b644b6f99b5f5d2977cd330/artifacts/grid_search__1',\n",
    "    'mlruns/341394191058264205/dfd8370927da40b68ef30b34e47693ff/artifacts/grid_search__3',\n",
    "    'mlruns/341394191058264205/4b14ccce89d9481586ae1856a56a5e66/artifacts/grid_search__5',\n",
    "    \n",
    "    \n",
    "    ]\n",
    "\n",
    "test(model_paths,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
