{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "def input_mlflow(cv_r_v,increment_number,X_train, y_train,pipeline,run_name,experiment_id,X_test,y_test):\n",
    "    \n",
    "\n",
    "    for wi in range(len(cv_r_v)):\n",
    "        \n",
    "        #====================skema===================\n",
    "        cols_spec = []\n",
    "        data_map = {\n",
    "                'int64': 'integer',\n",
    "                'float64': 'double',\n",
    "                'bool': 'boolean',\n",
    "                'str': 'string',\n",
    "                'object': 'string',\n",
    "                \"date\": 'datetime'\n",
    "            }\n",
    "\n",
    "        for name, dtype in X_train.dtypes.to_dict().items():\n",
    "            cols_spec.append(ColSpec(name=name, type=data_map[str(dtype)]))\n",
    "        input_schema = Schema(inputs=cols_spec)\n",
    "        output_schema = Schema([ColSpec(name=\"label\", type=\"string\")])\n",
    "        #parameter = ParamSpec(name=\"model_name\", dtype=\"string\", default=\"model1\")\n",
    "        #param_schema = ParamSchema(params=[parameter])\n",
    "        model_signature = ModelSignature(inputs=input_schema, outputs=output_schema)#, params=param_schema)\n",
    "        #print(\"MODEL SIGNATURE\")\n",
    "        #print(model_signature.to_dict())\n",
    "\n",
    "        model_signature = infer_signature(X_train, y_train)#, params={\"model_name\": \"model1\"})\n",
    "        #print(\"MODEL SIGNATURE\")\n",
    "        #print(model_signature.to_dict())\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #====================buat run baru===================\n",
    "        run_name_with_increment = f\"{run_name}__{increment_number}\"\n",
    "            # Membuka run MLflow\n",
    "        with mlflow.start_run(run_name=run_name_with_increment, experiment_id=experiment_id) as run:\n",
    "            # Mendapatkan run_id\n",
    "            run_id = mlflow.active_run().info.run_id\n",
    "        \n",
    "        print(f\"mlruns/{experiment_id}/{run_id}/artifacts/grid_search__{increment_number}\")\n",
    "        increment_number=increment_number+1\n",
    "        \n",
    "        \n",
    "        #====================buat parameter model dan metric===================\n",
    "\n",
    "        # Definisikan grid parameter untuk dicari\n",
    "        param_grid = cv_r_v[wi]\n",
    "        \n",
    "        #====================model===================\n",
    "\n",
    "        # Inisialisasi GridSearchCV\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5,  scoring='accuracy')\n",
    "\n",
    "        # Lakukan pencarian grid\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "            \n",
    "        #====================parameter===================\n",
    "        pipe=grid_search.best_estimator_\n",
    "        \n",
    "        \n",
    "        first_step_name = list(pipe.named_steps.keys())[0:len(pipe)]\n",
    "        \n",
    "\n",
    "        for i in range(len(pipe)):\n",
    "            # Mendapatkan parameter dari langkah 'sca'\n",
    "            nama=first_step_name[i]\n",
    "            sca_params = pipe.get_params()[nama]\n",
    "\n",
    "                # Membuka run MLflow\n",
    "            with mlflow.start_run( experiment_id=experiment_id,run_id=run_id) as run:\n",
    "\n",
    "                # Log parameter secara otomatis menggunakan loop\n",
    "                for param_name, param_value in sca_params.get_params().items():\n",
    "                    param_name=nama+'__'+param_name\n",
    "                    #print(param_name,param_value)\n",
    "                    mlflow.log_param(param_name, param_value)\n",
    "                    \n",
    "                    \n",
    "                #====================metric===================\n",
    "                #matric\n",
    "                hasil_test=grid_search.predict(X_test)\n",
    " \n",
    "                \n",
    "                \n",
    "                \n",
    "                                # Menghitung akurasi\n",
    "                accuracy = accuracy_score(y_test, hasil_test)\n",
    "\n",
    "                # Menghitung F1 score\n",
    "                f1 = f1_score(y_test, hasil_test,average='macro')\n",
    "\n",
    "                # Menghitung recall\n",
    "                recall = recall_score(y_test, hasil_test,average='macro')\n",
    "\n",
    "                \n",
    "                \n",
    "                                # Menghitung precision\n",
    "                precision = precision_score(y_test, hasil_test,average='macro')\n",
    "\n",
    "\n",
    "   \n",
    "                \n",
    "\n",
    "                # log model \n",
    "                mlflow.sklearn.log_model(sk_model=grid_search, artifact_path=\"grid_search__\"+str(increment_number-1),signature=model_signature)\n",
    "\n",
    "                metrics = {\n",
    "                    'mean_test_score':pd.DataFrame(grid_search.cv_results_)['mean_test_score'].values[0],\n",
    "                    \"accuracy\": accuracy,\n",
    "                    \"f1\": f1,\n",
    "                    \"recall\": recall,\n",
    "                    \"precision\": precision,\n",
    "         \n",
    "                }\n",
    "\n",
    "                mlflow.log_metrics(metrics)\n",
    "                \n",
    "                \n",
    "        mlflow.end_run()\n",
    "    print('selesai')\n",
    "\n",
    "        \n",
    "    return increment_number\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "def ambil_best(grid_search,n):\n",
    "    cv_r=grid_search.copy()\n",
    "    cv_r_v=cv_r.sort_values(by=['mean_test_score', 'std_test_score'], ascending=[False, True])\n",
    "    cv_r_v=cv_r_v.head(n)['params'].values\n",
    "\n",
    "    for wi in range(len(cv_r_v)):\n",
    "\n",
    "        for i in list(cv_r_v[wi]):\n",
    "\n",
    "            cv_r_v[wi][i]=[cv_r_v[wi][i]]\n",
    "\n",
    "\n",
    "    return cv_r_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def test(model_paths,X_test2,y_test):\n",
    "    ii=1\n",
    "    for i, model_path in enumerate(model_paths, start=1):\n",
    "        print(f'\\n\\n================================| model {ii} |==========================================')\n",
    "        \n",
    "        model = mlflow.sklearn.load_model(model_path)\n",
    "        y_pred = model.predict(X_test2)\n",
    "        print(f\"Classification Report for model {model_path[-2:]}:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(f\"Confusion Matrix for model {model_path[-2:]}:\\n\", confusion_matrix(y_test, y_pred), '\\n\\n')\n",
    "        \n",
    "        ii=ii+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import shapiro,normaltest,kstest,jarque_bera\n",
    "import pingouin as pg\n",
    "from pingouin import kruskal\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.types.schema import Schema\n",
    "from mlflow.types.schema import ParamSchema\n",
    "from mlflow.types.schema import ParamSpec\n",
    "from mlflow.types.schema import ColSpec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data_csv/data_bersih.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "144           6.7          3.0           5.2          2.3  virginica\n",
       "145           6.3          2.5           5.0          1.9  virginica\n",
       "146           6.5          3.0           5.2          2.0  virginica\n",
       "147           6.2          3.4           5.4          2.3  virginica\n",
       "148           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[149 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('species',axis=1)\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=141)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setosa        36\n",
       "versicolor    35\n",
       "virginica     33\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "virginica     17\n",
       "versicolor    15\n",
       "setosa        13\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal_length    1.028542\n",
       "petal_width     0.973123\n",
       "sepal_length    0.470557\n",
       "sepal_width     0.225195\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mutual_info=mutual_info_classif(X_train, y_train)\n",
    "\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X.columns\n",
    "mutual_info.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scatler = StandardScaler()\n",
    "log_model = LogisticRegression(max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opera=[('StandardScaler',scatler),('LogisticRegression',log_model)]\n",
    "pipeline=Pipeline(opera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model  try all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 {color: black;background-color: white;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 pre{padding: 0;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-toggleable {background-color: white;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-estimator:hover {background-color: #d4ebff;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-item {z-index: 1;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-parallel-item:only-child::after {width: 0;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-ebdafd22-33d9-498b-bd23-dfa725b022c0 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-ebdafd22-33d9-498b-bd23-dfa725b022c0\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                (&#x27;LogisticRegression&#x27;, LogisticRegression(max_iter=10000))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"158c3324-e02d-417e-ac19-b9fc55c3fa11\" type=\"checkbox\" ><label for=\"158c3324-e02d-417e-ac19-b9fc55c3fa11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                (&#x27;LogisticRegression&#x27;, LogisticRegression(max_iter=10000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4c810450-127b-4d9d-bd73-741fe2943bbb\" type=\"checkbox\" ><label for=\"4c810450-127b-4d9d-bd73-741fe2943bbb\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d2128109-b834-4574-b2c3-e6209e8bbbbe\" type=\"checkbox\" ><label for=\"d2128109-b834-4574-b2c3-e6209e8bbbbe\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('StandardScaler', StandardScaler()),\n",
       "                ('LogisticRegression', LogisticRegression(max_iter=10000))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## param_grid_lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lbfgs = {\n",
    "    'LogisticRegression__tol': np.linspace(0.001, 10, 5),\n",
    "    'LogisticRegression__C': np.linspace(0.001, 10, 5),\n",
    "    'LogisticRegression__solver': ['lbfgs'],\n",
    "    'LogisticRegression__penalty': ['l2', 'none']  # Perbaikan penulisan untuk 'none'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 {color: black;background-color: white;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 pre{padding: 0;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-toggleable {background-color: white;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-item {z-index: 1;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-parallel-item:only-child::after {width: 0;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-4eae7df9-c909-43c7-bb4e-cda1561283b9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-4eae7df9-c909-43c7-bb4e-cda1561283b9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;LogisticRegression&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={&#x27;LogisticRegression__C&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         &#x27;LogisticRegression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;LogisticRegression__solver&#x27;: [&#x27;lbfgs&#x27;],\n",
       "                         &#x27;LogisticRegression__tol&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"915d2425-39ae-4f63-b854-65e58d1f0453\" type=\"checkbox\" ><label for=\"915d2425-39ae-4f63-b854-65e58d1f0453\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;LogisticRegression&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={&#x27;LogisticRegression__C&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         &#x27;LogisticRegression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;LogisticRegression__solver&#x27;: [&#x27;lbfgs&#x27;],\n",
       "                         &#x27;LogisticRegression__tol&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2f3ac2c0-de1d-409d-8c35-58bf881a64a3\" type=\"checkbox\" ><label for=\"2f3ac2c0-de1d-409d-8c35-58bf881a64a3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b277cfbe-523f-4a41-8359-cf48c8b86f2f\" type=\"checkbox\" ><label for=\"b277cfbe-523f-4a41-8359-cf48c8b86f2f\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('StandardScaler', StandardScaler()),\n",
       "                                       ('LogisticRegression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'LogisticRegression__C': array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         'LogisticRegression__penalty': ['l2', 'none'],\n",
       "                         'LogisticRegression__solver': ['lbfgs'],\n",
       "                         'LogisticRegression__tol': array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid_lbfgs , cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_LogisticRegression__C</th>\n",
       "      <th>param_LogisticRegression__penalty</th>\n",
       "      <th>param_LogisticRegression__solver</th>\n",
       "      <th>param_LogisticRegression__tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.016840</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.951905</td>\n",
       "      <td>0.030132</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014764</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.942381</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.022462</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.932381</td>\n",
       "      <td>0.024541</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010125</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.003579</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.884762</td>\n",
       "      <td>0.048225</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.009826</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.875238</td>\n",
       "      <td>0.037423</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.013378</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.817143</td>\n",
       "      <td>0.036341</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015739</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.807619</td>\n",
       "      <td>0.042762</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.008595</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.798095</td>\n",
       "      <td>0.035328</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017643</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.722381</td>\n",
       "      <td>0.079619</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "10       0.016840      0.004868         0.004256        0.006092   \n",
       "21       0.014258      0.001926         0.001506        0.002108   \n",
       "6        0.014764      0.003057         0.000835        0.001670   \n",
       "5        0.022462      0.006120         0.002663        0.003871   \n",
       "7        0.010125      0.005416         0.003579        0.003274   \n",
       "12       0.009826      0.006133         0.000366        0.000733   \n",
       "8        0.013378      0.002090         0.002691        0.002200   \n",
       "1        0.015739      0.000180         0.000000        0.000000   \n",
       "9        0.008595      0.003901         0.002115        0.003967   \n",
       "0        0.017643      0.010607         0.005239        0.005829   \n",
       "\n",
       "   param_LogisticRegression__C param_LogisticRegression__penalty  \\\n",
       "10                     2.50075                                l2   \n",
       "21                      5.0005                                l2   \n",
       "6                        0.001                              none   \n",
       "5                        0.001                              none   \n",
       "7                        0.001                              none   \n",
       "12                     2.50075                                l2   \n",
       "8                        0.001                              none   \n",
       "1                        0.001                                l2   \n",
       "9                        0.001                              none   \n",
       "0                        0.001                                l2   \n",
       "\n",
       "   param_LogisticRegression__solver param_LogisticRegression__tol  \\\n",
       "10                            lbfgs                         0.001   \n",
       "21                            lbfgs                       2.50075   \n",
       "6                             lbfgs                       2.50075   \n",
       "5                             lbfgs                         0.001   \n",
       "7                             lbfgs                        5.0005   \n",
       "12                            lbfgs                        5.0005   \n",
       "8                             lbfgs                       7.50025   \n",
       "1                             lbfgs                       2.50075   \n",
       "9                             lbfgs                          10.0   \n",
       "0                             lbfgs                         0.001   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "10  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "21  {'LogisticRegression__C': 5.000500000000001, '...           1.000000   \n",
       "6   {'LogisticRegression__C': 0.001, 'LogisticRegr...           1.000000   \n",
       "5   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.952381   \n",
       "7   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.904762   \n",
       "12  {'LogisticRegression__C': 2.50075, 'LogisticRe...           0.904762   \n",
       "8   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.761905   \n",
       "1   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.761905   \n",
       "9   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.761905   \n",
       "0   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.714286   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "10           0.952381           0.952381           0.952381   \n",
       "21           0.952381           0.952381           0.904762   \n",
       "6            0.904762           0.952381           0.904762   \n",
       "5            0.952381           0.904762           0.952381   \n",
       "7            0.952381           0.809524           0.857143   \n",
       "12           0.904762           0.809524           0.857143   \n",
       "8            0.857143           0.809524           0.857143   \n",
       "1            0.857143           0.857143           0.761905   \n",
       "9            0.857143           0.809524           0.761905   \n",
       "0            0.666667           0.619048           0.761905   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "10               1.00         0.971429        0.023328                1  \n",
       "21               0.95         0.951905        0.030132                5  \n",
       "6                0.95         0.942381        0.035520                8  \n",
       "5                0.90         0.932381        0.024541               14  \n",
       "7                0.90         0.884762        0.048225               19  \n",
       "12               0.90         0.875238        0.037423               27  \n",
       "8                0.80         0.817143        0.036341               28  \n",
       "1                0.80         0.807619        0.042762               37  \n",
       "9                0.80         0.798095        0.035328               41  \n",
       "0                0.85         0.722381        0.079619               50  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.DataFrame(grid_search.cv_results_)\n",
    "df_1.drop_duplicates(subset=['mean_test_score', 'std_test_score', 'rank_test_score'], inplace=True)\n",
    "df_1 = df_1.sort_values(by=['mean_test_score', 'std_test_score'], ascending=[False, True])\n",
    "df_1.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## param_grid_newton-cg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 {color: black;background-color: white;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 pre{padding: 0;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-toggleable {background-color: white;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-estimator:hover {background-color: #d4ebff;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-item {z-index: 1;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-parallel-item:only-child::after {width: 0;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-c2d54c6d-7ea0-490f-974f-c2aa5194f476\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;LogisticRegression&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={&#x27;LogisticRegression__C&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         &#x27;LogisticRegression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;LogisticRegression__solver&#x27;: [&#x27;newton-cg&#x27;],\n",
       "                         &#x27;LogisticRegression__tol&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b7bcfdd1-5205-4877-9bf6-3f76bdcd4d0e\" type=\"checkbox\" ><label for=\"b7bcfdd1-5205-4877-9bf6-3f76bdcd4d0e\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;LogisticRegression&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={&#x27;LogisticRegression__C&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         &#x27;LogisticRegression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;LogisticRegression__solver&#x27;: [&#x27;newton-cg&#x27;],\n",
       "                         &#x27;LogisticRegression__tol&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"606283e9-bb46-4e46-9354-5abb5467870b\" type=\"checkbox\" ><label for=\"606283e9-bb46-4e46-9354-5abb5467870b\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9674cf24-4fcd-430b-99b3-5ba0c37d84f0\" type=\"checkbox\" ><label for=\"9674cf24-4fcd-430b-99b3-5ba0c37d84f0\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('StandardScaler', StandardScaler()),\n",
       "                                       ('LogisticRegression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'LogisticRegression__C': array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         'LogisticRegression__penalty': ['l2', 'none'],\n",
       "                         'LogisticRegression__solver': ['newton-cg'],\n",
       "                         'LogisticRegression__tol': array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_newton = {\n",
    "    'LogisticRegression__tol': np.linspace(0.001, 10, 5),\n",
    "    'LogisticRegression__C': np.linspace(0.001, 10, 5),\n",
    "    'LogisticRegression__solver': ['newton-cg'],\n",
    "    'LogisticRegression__penalty': ['l2', 'none']  # Perbaikan penulisan untuk 'none'\n",
    "}\n",
    "\n",
    "# Inisialisasi GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid_newton , cv=5, scoring='accuracy')\n",
    "\n",
    "# Lakukan pencarian grid\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_LogisticRegression__C</th>\n",
       "      <th>param_LogisticRegression__penalty</th>\n",
       "      <th>param_LogisticRegression__solver</th>\n",
       "      <th>param_LogisticRegression__tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.008910</td>\n",
       "      <td>0.007346</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.951905</td>\n",
       "      <td>0.030132</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.045961</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.932381</td>\n",
       "      <td>0.024541</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.885238</td>\n",
       "      <td>0.047913</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.006867</td>\n",
       "      <td>0.007384</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.845714</td>\n",
       "      <td>0.037808</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009372</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.807619</td>\n",
       "      <td>0.042762</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020658</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.722381</td>\n",
       "      <td>0.079619</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6        0.000511      0.001022         0.008910        0.007346   \n",
       "11       0.010250      0.003286         0.003384        0.004125   \n",
       "5        0.045961      0.012108         0.004846        0.006901   \n",
       "7        0.012817      0.006187         0.003156        0.006312   \n",
       "8        0.006867      0.007384         0.006304        0.006724   \n",
       "1        0.009372      0.007652         0.005980        0.006603   \n",
       "0        0.020658      0.005332         0.001351        0.001711   \n",
       "\n",
       "   param_LogisticRegression__C param_LogisticRegression__penalty  \\\n",
       "6                        0.001                              none   \n",
       "11                     2.50075                                l2   \n",
       "5                        0.001                              none   \n",
       "7                        0.001                              none   \n",
       "8                        0.001                              none   \n",
       "1                        0.001                                l2   \n",
       "0                        0.001                                l2   \n",
       "\n",
       "   param_LogisticRegression__solver param_LogisticRegression__tol  \\\n",
       "6                         newton-cg                       2.50075   \n",
       "11                        newton-cg                       2.50075   \n",
       "5                         newton-cg                         0.001   \n",
       "7                         newton-cg                        5.0005   \n",
       "8                         newton-cg                       7.50025   \n",
       "1                         newton-cg                       2.50075   \n",
       "0                         newton-cg                         0.001   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "6   {'LogisticRegression__C': 0.001, 'LogisticRegr...           1.000000   \n",
       "11  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "5   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.952381   \n",
       "7   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.809524   \n",
       "8   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.809524   \n",
       "1   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.761905   \n",
       "0   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.714286   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "6            0.952381           0.952381           0.952381   \n",
       "11           0.904762           0.952381           0.952381   \n",
       "5            0.952381           0.904762           0.952381   \n",
       "7            0.904762           0.904762           0.857143   \n",
       "8            0.857143           0.904762           0.857143   \n",
       "1            0.857143           0.857143           0.761905   \n",
       "0            0.666667           0.619048           0.761905   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "6                1.00         0.971429        0.023328                1  \n",
       "11               0.95         0.951905        0.030132               12  \n",
       "5                0.90         0.932381        0.024541               14  \n",
       "7                0.95         0.885238        0.047913               19  \n",
       "8                0.80         0.845714        0.037808               28  \n",
       "1                0.80         0.807619        0.042762               37  \n",
       "0                0.85         0.722381        0.079619               50  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.DataFrame(grid_search.cv_results_)\n",
    "df_2.drop_duplicates(subset=['mean_test_score', 'std_test_score', 'rank_test_score'], inplace=True)\n",
    "df_2 = df_2.sort_values(by=['mean_test_score', 'std_test_score'], ascending=[False, True])\n",
    "df_2.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## param_grid_liblinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 {color: black;background-color: white;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 pre{padding: 0;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-toggleable {background-color: white;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-estimator:hover {background-color: #d4ebff;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-item {z-index: 1;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-parallel-item:only-child::after {width: 0;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-9fb4e7af-ea1f-428f-9fdf-376bc5801563\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;LogisticRegression&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={&#x27;LogisticRegression__C&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         &#x27;LogisticRegression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;],\n",
       "                         &#x27;LogisticRegression__solver&#x27;: [&#x27;liblinear&#x27;],\n",
       "                         &#x27;LogisticRegression__tol&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b9e6624e-d352-4f98-97d9-af8da4729468\" type=\"checkbox\" ><label for=\"b9e6624e-d352-4f98-97d9-af8da4729468\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;LogisticRegression&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={&#x27;LogisticRegression__C&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         &#x27;LogisticRegression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;],\n",
       "                         &#x27;LogisticRegression__solver&#x27;: [&#x27;liblinear&#x27;],\n",
       "                         &#x27;LogisticRegression__tol&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"94ebb538-c75a-4da3-9a82-175ed1eed491\" type=\"checkbox\" ><label for=\"94ebb538-c75a-4da3-9a82-175ed1eed491\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6a202637-6401-45f5-a926-e97f6bc72e9d\" type=\"checkbox\" ><label for=\"6a202637-6401-45f5-a926-e97f6bc72e9d\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('StandardScaler', StandardScaler()),\n",
       "                                       ('LogisticRegression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'LogisticRegression__C': array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         'LogisticRegression__penalty': ['l2', 'l1'],\n",
       "                         'LogisticRegression__solver': ['liblinear'],\n",
       "                         'LogisticRegression__tol': array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_liblinear = {\n",
    "    'LogisticRegression__tol': np.linspace(0.001, 10,5),\n",
    "    'LogisticRegression__C': np.linspace(0.001, 10, 5),\n",
    "    'LogisticRegression__solver': ['liblinear'],\n",
    "    'LogisticRegression__penalty': ['l2', 'l1']  \n",
    "}\n",
    "\n",
    "# Inisialisasi GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid_liblinear , cv=5, scoring='accuracy')\n",
    "\n",
    "# Lakukan pencarian grid\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_LogisticRegression__C</th>\n",
       "      <th>param_LogisticRegression__penalty</th>\n",
       "      <th>param_LogisticRegression__solver</th>\n",
       "      <th>param_LogisticRegression__tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.007878</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.942381</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.007504</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.932857</td>\n",
       "      <td>0.037868</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 10.0, 'LogisticRegre...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.022758</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.006192</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.913810</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.904286</td>\n",
       "      <td>0.029370</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.007988</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 10.0, 'LogisticRegre...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.836190</td>\n",
       "      <td>0.049816</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 7.50025, 'LogisticRe...</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.049450</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.817619</td>\n",
       "      <td>0.034193</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009945</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.807619</td>\n",
       "      <td>0.042762</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.789048</td>\n",
       "      <td>0.055525</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "25       0.007878      0.004552         0.000979        0.001251   \n",
       "15       0.007504      0.003007         0.001065        0.001305   \n",
       "40       0.003429      0.006008         0.003598        0.006944   \n",
       "20       0.006192      0.005764         0.001365        0.001829   \n",
       "10       0.006471      0.004612         0.001423        0.001977   \n",
       "46       0.007828      0.007988         0.001135        0.001390   \n",
       "36       0.007801      0.005173         0.002940        0.003946   \n",
       "16       0.006673      0.006486         0.004439        0.004875   \n",
       "0        0.009945      0.005169         0.002393        0.003093   \n",
       "26       0.003202      0.005247         0.006266        0.007674   \n",
       "\n",
       "   param_LogisticRegression__C param_LogisticRegression__penalty  \\\n",
       "25                      5.0005                                l1   \n",
       "15                     2.50075                                l1   \n",
       "40                        10.0                                l2   \n",
       "20                      5.0005                                l2   \n",
       "10                     2.50075                                l2   \n",
       "46                        10.0                                l1   \n",
       "36                     7.50025                                l1   \n",
       "16                     2.50075                                l1   \n",
       "0                        0.001                                l2   \n",
       "26                      5.0005                                l1   \n",
       "\n",
       "   param_LogisticRegression__solver param_LogisticRegression__tol  \\\n",
       "25                        liblinear                         0.001   \n",
       "15                        liblinear                         0.001   \n",
       "40                        liblinear                         0.001   \n",
       "20                        liblinear                         0.001   \n",
       "10                        liblinear                         0.001   \n",
       "46                        liblinear                       2.50075   \n",
       "36                        liblinear                       2.50075   \n",
       "16                        liblinear                       2.50075   \n",
       "0                         liblinear                         0.001   \n",
       "26                        liblinear                       2.50075   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "25  {'LogisticRegression__C': 5.000500000000001, '...           1.000000   \n",
       "15  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "40  {'LogisticRegression__C': 10.0, 'LogisticRegre...           0.952381   \n",
       "20  {'LogisticRegression__C': 5.000500000000001, '...           0.952381   \n",
       "10  {'LogisticRegression__C': 2.50075, 'LogisticRe...           0.904762   \n",
       "46  {'LogisticRegression__C': 10.0, 'LogisticRegre...           0.857143   \n",
       "36  {'LogisticRegression__C': 7.50025, 'LogisticRe...           0.761905   \n",
       "16  {'LogisticRegression__C': 2.50075, 'LogisticRe...           0.857143   \n",
       "0   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.761905   \n",
       "26  {'LogisticRegression__C': 5.000500000000001, '...           0.714286   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "25           0.904762           0.904762           0.952381   \n",
       "15           0.904762           0.904762           0.904762   \n",
       "40           0.904762           0.904762           0.904762   \n",
       "20           0.904762           0.904762           0.857143   \n",
       "10           0.904762           0.904762           0.857143   \n",
       "46           0.904762           0.857143           0.761905   \n",
       "36           0.857143           0.904762           0.809524   \n",
       "16           0.809524           0.761905           0.809524   \n",
       "0            0.857143           0.857143           0.761905   \n",
       "26           0.857143           0.761905           0.761905   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "25               0.95         0.942381        0.035520                1  \n",
       "15               0.95         0.932857        0.037868                4  \n",
       "40               0.95         0.923333        0.022758                5  \n",
       "20               0.95         0.913810        0.035135                6  \n",
       "10               0.95         0.904286        0.029370                8  \n",
       "46               0.80         0.836190        0.049816                9  \n",
       "36               0.80         0.826667        0.049450               10  \n",
       "16               0.85         0.817619        0.034193               11  \n",
       "0                0.80         0.807619        0.042762               12  \n",
       "26               0.85         0.789048        0.055525               14  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3 = pd.DataFrame(grid_search.cv_results_)\n",
    "df_3.drop_duplicates(subset=['mean_test_score', 'std_test_score', 'rank_test_score'], inplace=True)\n",
    "df_3 = df_3.sort_values(by=['mean_test_score', 'std_test_score'], ascending=[False, True])\n",
    "df_3.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## param_grid_sag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 {color: black;background-color: white;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 pre{padding: 0;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-toggleable {background-color: white;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-estimator:hover {background-color: #d4ebff;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-item {z-index: 1;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-parallel-item:only-child::after {width: 0;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-be2f0530-cb83-4e82-b3de-5173d6e36d42 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-be2f0530-cb83-4e82-b3de-5173d6e36d42\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;LogisticRegression&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={&#x27;LogisticRegression__C&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         &#x27;LogisticRegression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;LogisticRegression__solver&#x27;: [&#x27;sag&#x27;],\n",
       "                         &#x27;LogisticRegression__tol&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1ce422bf-7d41-4a6b-9f5e-22fec3274372\" type=\"checkbox\" ><label for=\"1ce422bf-7d41-4a6b-9f5e-22fec3274372\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;LogisticRegression&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={&#x27;LogisticRegression__C&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         &#x27;LogisticRegression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;LogisticRegression__solver&#x27;: [&#x27;sag&#x27;],\n",
       "                         &#x27;LogisticRegression__tol&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a90a928c-7fb8-4878-99ae-32ebb25fa8c4\" type=\"checkbox\" ><label for=\"a90a928c-7fb8-4878-99ae-32ebb25fa8c4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"11d52152-b786-411d-bdb2-7779c9b759cb\" type=\"checkbox\" ><label for=\"11d52152-b786-411d-bdb2-7779c9b759cb\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('StandardScaler', StandardScaler()),\n",
       "                                       ('LogisticRegression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'LogisticRegression__C': array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         'LogisticRegression__penalty': ['l2', 'none'],\n",
       "                         'LogisticRegression__solver': ['sag'],\n",
       "                         'LogisticRegression__tol': array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param_grid_sag = {\n",
    "    'LogisticRegression__tol': np.linspace(0.001, 10, 5),\n",
    "    'LogisticRegression__C': np.linspace(0.001, 10, 5),\n",
    "    'LogisticRegression__solver': ['sag'],\n",
    "    'LogisticRegression__penalty': ['l2', 'none']  \n",
    "}\n",
    "\n",
    "# Inisialisasi GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid_sag , cv=5, scoring='accuracy')\n",
    "\n",
    "# Lakukan pencarian grid\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_LogisticRegression__C</th>\n",
       "      <th>param_LogisticRegression__penalty</th>\n",
       "      <th>param_LogisticRegression__solver</th>\n",
       "      <th>param_LogisticRegression__tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012792</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015859</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.942381</td>\n",
       "      <td>0.018832</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.011882</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.932381</td>\n",
       "      <td>0.038850</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>10.0</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 10.0, 'LogisticRegre...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.063346</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.015773</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.076333</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.009304</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 7.50025, 'LogisticRe...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.019611</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.008946</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>{'LogisticRegression__C': 7.50025, 'LogisticRe...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.904286</td>\n",
       "      <td>0.067013</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.006318</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.903810</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.004912</td>\n",
       "      <td>0.006238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.903810</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.007871</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 10.0, 'LogisticRegre...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.894762</td>\n",
       "      <td>0.055049</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "10       0.012792      0.002681         0.000744        0.001489   \n",
       "5        0.015859      0.002999         0.002895        0.004893   \n",
       "16       0.011882      0.005017         0.000807        0.001614   \n",
       "46       0.006832      0.007631         0.002907        0.005814   \n",
       "14       0.015773      0.001579         0.000000        0.000000   \n",
       "38       0.009304      0.002251         0.002011        0.002597   \n",
       "37       0.008946      0.005441         0.003508        0.005909   \n",
       "19       0.007512      0.006318         0.000664        0.000910   \n",
       "22       0.004912      0.006238         0.000000        0.000000   \n",
       "48       0.007871      0.007525         0.000000        0.000000   \n",
       "\n",
       "   param_LogisticRegression__C param_LogisticRegression__penalty  \\\n",
       "10                     2.50075                                l2   \n",
       "5                        0.001                              none   \n",
       "16                     2.50075                              none   \n",
       "46                        10.0                              none   \n",
       "14                     2.50075                                l2   \n",
       "38                     7.50025                              none   \n",
       "37                     7.50025                              none   \n",
       "19                     2.50075                              none   \n",
       "22                      5.0005                                l2   \n",
       "48                        10.0                              none   \n",
       "\n",
       "   param_LogisticRegression__solver param_LogisticRegression__tol  \\\n",
       "10                              sag                         0.001   \n",
       "5                               sag                         0.001   \n",
       "16                              sag                       2.50075   \n",
       "46                              sag                       2.50075   \n",
       "14                              sag                          10.0   \n",
       "38                              sag                       7.50025   \n",
       "37                              sag                        5.0005   \n",
       "19                              sag                          10.0   \n",
       "22                              sag                        5.0005   \n",
       "48                              sag                       7.50025   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "10  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "5   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.952381   \n",
       "16  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "46  {'LogisticRegression__C': 10.0, 'LogisticRegre...           0.809524   \n",
       "14  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "38  {'LogisticRegression__C': 7.50025, 'LogisticRe...           0.904762   \n",
       "37  {'LogisticRegression__C': 7.50025, 'LogisticRe...           0.904762   \n",
       "19  {'LogisticRegression__C': 2.50075, 'LogisticRe...           0.904762   \n",
       "22  {'LogisticRegression__C': 5.000500000000001, '...           0.952381   \n",
       "48  {'LogisticRegression__C': 10.0, 'LogisticRegre...           0.952381   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "10           0.952381           0.952381           0.952381   \n",
       "5            0.952381           0.904762           0.952381   \n",
       "16           0.904762           0.952381           0.904762   \n",
       "46           0.904762           0.952381           1.000000   \n",
       "14           0.857143           1.000000           0.809524   \n",
       "38           0.952381           0.904762           0.904762   \n",
       "37           0.857143           1.000000           0.809524   \n",
       "19           0.952381           0.904762           0.857143   \n",
       "22           0.857143           1.000000           0.809524   \n",
       "48           0.904762           0.857143           0.809524   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "10               1.00         0.971429        0.023328                1  \n",
       "5                0.95         0.942381        0.018832                5  \n",
       "16               0.90         0.932381        0.038850               10  \n",
       "46               0.90         0.913333        0.063346               11  \n",
       "14               0.90         0.913333        0.076333               11  \n",
       "38               0.90         0.913333        0.019611               13  \n",
       "37               0.95         0.904286        0.067013               14  \n",
       "19               0.90         0.903810        0.030177               15  \n",
       "22               0.90         0.903810        0.067370               15  \n",
       "48               0.95         0.894762        0.055049               17  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4 = pd.DataFrame(grid_search.cv_results_)\n",
    "df_4.drop_duplicates(subset=['mean_test_score', 'std_test_score', 'rank_test_score'], inplace=True)\n",
    "df_4 = df_4.sort_values(by=['mean_test_score', 'std_test_score'], ascending=[False, True])\n",
    "df_4.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## param_grid_saga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 {color: black;background-color: white;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 pre{padding: 0;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-toggleable {background-color: white;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-estimator:hover {background-color: #d4ebff;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-item {z-index: 1;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-parallel-item:only-child::after {width: 0;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-1e9070b1-9759-4c17-a2ec-3b621a4eec04\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;LogisticRegression&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={&#x27;LogisticRegression__C&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         &#x27;LogisticRegression__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;LogisticRegression__solver&#x27;: [&#x27;saga&#x27;],\n",
       "                         &#x27;LogisticRegression__tol&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7512e92e-ee89-48e4-a277-f9fe80136fcd\" type=\"checkbox\" ><label for=\"7512e92e-ee89-48e4-a277-f9fe80136fcd\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;LogisticRegression&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={&#x27;LogisticRegression__C&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         &#x27;LogisticRegression__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;LogisticRegression__solver&#x27;: [&#x27;saga&#x27;],\n",
       "                         &#x27;LogisticRegression__tol&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"032d39db-dc78-44cd-a919-492e85dffe48\" type=\"checkbox\" ><label for=\"032d39db-dc78-44cd-a919-492e85dffe48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f0d1b4e1-5dbd-4c5e-8806-b68b0f3acc7b\" type=\"checkbox\" ><label for=\"f0d1b4e1-5dbd-4c5e-8806-b68b0f3acc7b\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('StandardScaler', StandardScaler()),\n",
       "                                       ('LogisticRegression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'LogisticRegression__C': array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         'LogisticRegression__penalty': ['l1', 'l2', 'none'],\n",
       "                         'LogisticRegression__solver': ['saga'],\n",
       "                         'LogisticRegression__tol': array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_saga = {\n",
    "    'LogisticRegression__tol': np.linspace(0.001, 10, 5),\n",
    "    'LogisticRegression__C': np.linspace(0.001, 10, 5),\n",
    "    'LogisticRegression__solver': ['saga'],\n",
    "    'LogisticRegression__penalty': ['l1','l2', 'none'] \n",
    "}\n",
    "\n",
    "# Inisialisasi GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid_saga , cv=5, scoring='accuracy')\n",
    "\n",
    "# Lakukan pencarian grid\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_LogisticRegression__C</th>\n",
       "      <th>param_LogisticRegression__penalty</th>\n",
       "      <th>param_LogisticRegression__solver</th>\n",
       "      <th>param_LogisticRegression__tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.013218</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018918</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.008810</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.942381</td>\n",
       "      <td>0.018832</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.008385</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 7.50025, 'LogisticRe...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.056912</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'LogisticRegression__C': 7.50025, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.064902</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.038615</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.011012</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.038615</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.013567</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.922381</td>\n",
       "      <td>0.078645</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.007009</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.913810</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.007745</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>{'LogisticRegression__C': 10.0, 'LogisticRegre...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.082060</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.005232</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.912857</td>\n",
       "      <td>0.037964</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "15       0.013218      0.007248         0.006537        0.004744   \n",
       "10       0.018918      0.004652         0.007189        0.008810   \n",
       "51       0.008385      0.006459         0.003650        0.006107   \n",
       "54       0.008317      0.005373         0.002784        0.002618   \n",
       "43       0.004420      0.006345         0.009169        0.006629   \n",
       "42       0.011012      0.003403         0.002765        0.003770   \n",
       "29       0.013567      0.003822         0.001991        0.003982   \n",
       "34       0.007009      0.004099         0.001637        0.002070   \n",
       "62       0.009394      0.007745         0.000386        0.000773   \n",
       "18       0.005232      0.003020         0.005474        0.002121   \n",
       "\n",
       "   param_LogisticRegression__C param_LogisticRegression__penalty  \\\n",
       "15                     2.50075                                l1   \n",
       "10                       0.001                              none   \n",
       "51                     7.50025                                l2   \n",
       "54                     7.50025                                l2   \n",
       "43                      5.0005                              none   \n",
       "42                      5.0005                              none   \n",
       "29                     2.50075                              none   \n",
       "34                      5.0005                                l1   \n",
       "62                        10.0                                l1   \n",
       "18                     2.50075                                l1   \n",
       "\n",
       "   param_LogisticRegression__solver param_LogisticRegression__tol  \\\n",
       "15                             saga                         0.001   \n",
       "10                             saga                         0.001   \n",
       "51                             saga                       2.50075   \n",
       "54                             saga                          10.0   \n",
       "43                             saga                       7.50025   \n",
       "42                             saga                        5.0005   \n",
       "29                             saga                          10.0   \n",
       "34                             saga                          10.0   \n",
       "62                             saga                        5.0005   \n",
       "18                             saga                       7.50025   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "15  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "10  {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.952381   \n",
       "51  {'LogisticRegression__C': 7.50025, 'LogisticRe...           0.857143   \n",
       "54  {'LogisticRegression__C': 7.50025, 'LogisticRe...           1.000000   \n",
       "43  {'LogisticRegression__C': 5.000500000000001, '...           0.952381   \n",
       "42  {'LogisticRegression__C': 5.000500000000001, '...           1.000000   \n",
       "29  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "34  {'LogisticRegression__C': 5.000500000000001, '...           0.904762   \n",
       "62  {'LogisticRegression__C': 10.0, 'LogisticRegre...           0.952381   \n",
       "18  {'LogisticRegression__C': 2.50075, 'LogisticRe...           0.904762   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "15           0.952381           0.952381           0.952381   \n",
       "10           0.952381           0.904762           0.952381   \n",
       "51           0.952381           1.000000           0.857143   \n",
       "54           0.857143           1.000000           0.857143   \n",
       "43           0.952381           0.952381           0.857143   \n",
       "42           0.904762           0.904762           0.904762   \n",
       "29           0.952381           1.000000           0.809524   \n",
       "34           0.904762           0.952381           0.857143   \n",
       "62           0.952381           1.000000           0.761905   \n",
       "18           0.952381           0.952381           0.904762   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15               1.00         0.971429        0.023328                1  \n",
       "10               0.95         0.942381        0.018832                9  \n",
       "51               0.95         0.923333        0.056912               14  \n",
       "54               0.90         0.922857        0.064902               15  \n",
       "43               0.90         0.922857        0.038615               16  \n",
       "42               0.90         0.922857        0.038615               16  \n",
       "29               0.85         0.922381        0.078645               18  \n",
       "34               0.95         0.913810        0.035135               19  \n",
       "62               0.90         0.913333        0.082060               21  \n",
       "18               0.85         0.912857        0.037964               22  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5 = pd.DataFrame(grid_search.cv_results_)\n",
    "df_5.drop_duplicates(subset=['mean_test_score', 'std_test_score', 'rank_test_score'], inplace=True)\n",
    "df_5 = df_5.sort_values(by=['mean_test_score', 'std_test_score'], ascending=[False, True])\n",
    "df_5.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 {color: black;background-color: white;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 pre{padding: 0;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-toggleable {background-color: white;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-item {z-index: 1;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-parallel-item:only-child::after {width: 0;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-3a71b1b8-f782-47d4-9d80-8549c2a676d1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;LogisticRegression&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={&#x27;LogisticRegression__C&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         &#x27;LogisticRegression__l1_ratio&#x27;: array([0.001]),\n",
       "                         &#x27;LogisticRegression__penalty&#x27;: [&#x27;elasticnet&#x27;],\n",
       "                         &#x27;LogisticRegression__solver&#x27;: [&#x27;saga&#x27;],\n",
       "                         &#x27;LogisticRegression__tol&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f71664f9-3f7f-494c-8bca-3c4f3bf879e9\" type=\"checkbox\" ><label for=\"f71664f9-3f7f-494c-8bca-3c4f3bf879e9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;LogisticRegression&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={&#x27;LogisticRegression__C&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         &#x27;LogisticRegression__l1_ratio&#x27;: array([0.001]),\n",
       "                         &#x27;LogisticRegression__penalty&#x27;: [&#x27;elasticnet&#x27;],\n",
       "                         &#x27;LogisticRegression__solver&#x27;: [&#x27;saga&#x27;],\n",
       "                         &#x27;LogisticRegression__tol&#x27;: array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6caa7051-4ad1-4421-af31-0ec548fbe547\" type=\"checkbox\" ><label for=\"6caa7051-4ad1-4421-af31-0ec548fbe547\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"80dcb631-5bf2-472c-bd1e-3e43cd2089e3\" type=\"checkbox\" ><label for=\"80dcb631-5bf2-472c-bd1e-3e43cd2089e3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('StandardScaler', StandardScaler()),\n",
       "                                       ('LogisticRegression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             param_grid={'LogisticRegression__C': array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01]),\n",
       "                         'LogisticRegression__l1_ratio': array([0.001]),\n",
       "                         'LogisticRegression__penalty': ['elasticnet'],\n",
       "                         'LogisticRegression__solver': ['saga'],\n",
       "                         'LogisticRegression__tol': array([1.00000e-03, 2.50075e+00, 5.00050e+00, 7.50025e+00, 1.00000e+01])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_saga2 = {\n",
    "    'LogisticRegression__tol': np.linspace(0.001, 10, 5),\n",
    "    'LogisticRegression__C': np.linspace(0.001, 10, 5),\n",
    "    'LogisticRegression__solver': ['saga'],\n",
    "    'LogisticRegression__l1_ratio': np.linspace(0.001, 10, 1),\n",
    "    'LogisticRegression__penalty': ['elasticnet']  \n",
    "}\n",
    "\n",
    "# Inisialisasi GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid_saga2 , cv=5, scoring='accuracy')\n",
    "\n",
    "# Lakukan pencarian grid\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_LogisticRegression__C</th>\n",
       "      <th>param_LogisticRegression__l1_ratio</th>\n",
       "      <th>param_LogisticRegression__penalty</th>\n",
       "      <th>param_LogisticRegression__solver</th>\n",
       "      <th>param_LogisticRegression__tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015228</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>0.001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 10.0, 'LogisticRegre...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>0.001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.064390</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.009128</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 10.0, 'LogisticRegre...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.913810</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>0.001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 7.50025, 'LogisticRe...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.019611</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008432</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>0.001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.894762</td>\n",
       "      <td>0.034876</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.893810</td>\n",
       "      <td>0.037240</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>0.005969</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'LogisticRegression__C': 10.0, 'LogisticRegre...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.885238</td>\n",
       "      <td>0.047913</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.004585</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>0.001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>{'LogisticRegression__C': 7.50025, 'LogisticRe...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.884762</td>\n",
       "      <td>0.048225</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>0.001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.884286</td>\n",
       "      <td>0.077950</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5        0.015228      0.002316         0.001010        0.002020   \n",
       "23       0.006941      0.006119         0.005993        0.004649   \n",
       "8        0.005971      0.003121         0.006903        0.008044   \n",
       "21       0.009128      0.007687         0.001991        0.002761   \n",
       "18       0.010734      0.006858         0.001603        0.003207   \n",
       "6        0.008432      0.005962         0.000000        0.000000   \n",
       "12       0.005233      0.005038         0.001415        0.001822   \n",
       "24       0.004017      0.003562         0.006450        0.005969   \n",
       "17       0.008362      0.006311         0.004340        0.004585   \n",
       "9        0.014017      0.003498         0.000914        0.001827   \n",
       "\n",
       "   param_LogisticRegression__C param_LogisticRegression__l1_ratio  \\\n",
       "5                      2.50075                              0.001   \n",
       "23                        10.0                              0.001   \n",
       "8                      2.50075                              0.001   \n",
       "21                        10.0                              0.001   \n",
       "18                     7.50025                              0.001   \n",
       "6                      2.50075                              0.001   \n",
       "12                      5.0005                              0.001   \n",
       "24                        10.0                              0.001   \n",
       "17                     7.50025                              0.001   \n",
       "9                      2.50075                              0.001   \n",
       "\n",
       "   param_LogisticRegression__penalty param_LogisticRegression__solver  \\\n",
       "5                         elasticnet                             saga   \n",
       "23                        elasticnet                             saga   \n",
       "8                         elasticnet                             saga   \n",
       "21                        elasticnet                             saga   \n",
       "18                        elasticnet                             saga   \n",
       "6                         elasticnet                             saga   \n",
       "12                        elasticnet                             saga   \n",
       "24                        elasticnet                             saga   \n",
       "17                        elasticnet                             saga   \n",
       "9                         elasticnet                             saga   \n",
       "\n",
       "   param_LogisticRegression__tol  \\\n",
       "5                          0.001   \n",
       "23                       7.50025   \n",
       "8                        7.50025   \n",
       "21                       2.50075   \n",
       "18                       7.50025   \n",
       "6                        2.50075   \n",
       "12                        5.0005   \n",
       "24                          10.0   \n",
       "17                        5.0005   \n",
       "9                           10.0   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "5   {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "23  {'LogisticRegression__C': 10.0, 'LogisticRegre...           1.000000   \n",
       "8   {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "21  {'LogisticRegression__C': 10.0, 'LogisticRegre...           0.904762   \n",
       "18  {'LogisticRegression__C': 7.50025, 'LogisticRe...           0.904762   \n",
       "6   {'LogisticRegression__C': 2.50075, 'LogisticRe...           0.904762   \n",
       "12  {'LogisticRegression__C': 5.000500000000001, '...           0.952381   \n",
       "24  {'LogisticRegression__C': 10.0, 'LogisticRegre...           0.809524   \n",
       "17  {'LogisticRegression__C': 7.50025, 'LogisticRe...           0.809524   \n",
       "9   {'LogisticRegression__C': 2.50075, 'LogisticRe...           0.809524   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "5            0.952381           0.952381           0.952381   \n",
       "23           0.904762           0.904762           0.857143   \n",
       "8            0.904762           0.952381           0.809524   \n",
       "21           0.904762           0.952381           0.857143   \n",
       "18           0.904762           0.952381           0.904762   \n",
       "6            0.904762           0.857143           0.857143   \n",
       "12           0.904762           0.904762           0.857143   \n",
       "24           0.904762           0.904762           0.857143   \n",
       "17           0.904762           0.952381           0.857143   \n",
       "9            0.952381           1.000000           0.809524   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "5                1.00         0.971429        0.023328                1  \n",
       "23               0.95         0.923333        0.048291                5  \n",
       "8                0.95         0.923333        0.064390                5  \n",
       "21               0.95         0.913810        0.035135                7  \n",
       "18               0.90         0.913333        0.019611                8  \n",
       "6                0.95         0.894762        0.034876                9  \n",
       "12               0.85         0.893810        0.037240               10  \n",
       "24               0.95         0.885238        0.047913               11  \n",
       "17               0.90         0.884762        0.048225               12  \n",
       "9                0.85         0.884286        0.077950               13  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_6 = pd.DataFrame(grid_search.cv_results_)\n",
    "df_6.drop_duplicates(subset=['mean_test_score', 'std_test_score', 'rank_test_score'], inplace=True)\n",
    "df_6 = df_6.sort_values(by=['mean_test_score', 'std_test_score'], ascending=[False, True])\n",
    "df_6.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gabung kan semua ambilyg top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_LogisticRegression__C</th>\n",
       "      <th>param_LogisticRegression__penalty</th>\n",
       "      <th>param_LogisticRegression__solver</th>\n",
       "      <th>param_LogisticRegression__tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>param_LogisticRegression__l1_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.016840</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.008910</td>\n",
       "      <td>0.007346</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012792</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.013218</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015228</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.951905</td>\n",
       "      <td>0.030132</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.951905</td>\n",
       "      <td>0.030132</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015859</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.942381</td>\n",
       "      <td>0.018832</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018918</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.008810</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.942381</td>\n",
       "      <td>0.018832</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.007878</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.942381</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014764</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.942381</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.007504</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.932857</td>\n",
       "      <td>0.037868</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.022462</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.932381</td>\n",
       "      <td>0.024541</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.045961</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.932381</td>\n",
       "      <td>0.024541</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.011882</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.932381</td>\n",
       "      <td>0.038850</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 10.0, 'LogisticRegre...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.022758</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>10.0</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 10.0, 'LogisticRegre...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.008385</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 7.50025, 'LogisticRe...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.056912</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.064390</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'LogisticRegression__C': 7.50025, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.064902</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>none</td>\n",
       "      <td>saga</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.038615</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.006192</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 5.000500000000001, '...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.913810</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.009128</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>10.0</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 10.0, 'LogisticRegre...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.913810</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>10.0</td>\n",
       "      <td>none</td>\n",
       "      <td>sag</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>{'LogisticRegression__C': 10.0, 'LogisticRegre...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.063346</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.015773</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.076333</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 7.50025, 'LogisticRe...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.019611</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>2.50075</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'LogisticRegression__C': 2.50075, 'LogisticRe...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.904286</td>\n",
       "      <td>0.029370</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.885238</td>\n",
       "      <td>0.047913</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010125</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.003579</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>5.0005</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.884762</td>\n",
       "      <td>0.048225</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.006867</td>\n",
       "      <td>0.007384</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.001</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>7.50025</td>\n",
       "      <td>{'LogisticRegression__C': 0.001, 'LogisticRegr...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.845714</td>\n",
       "      <td>0.037808</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "10       0.016840      0.004868         0.004256        0.006092   \n",
       "6        0.000511      0.001022         0.008910        0.007346   \n",
       "10       0.012792      0.002681         0.000744        0.001489   \n",
       "15       0.013218      0.007248         0.006537        0.004744   \n",
       "5        0.015228      0.002316         0.001010        0.002020   \n",
       "21       0.014258      0.001926         0.001506        0.002108   \n",
       "11       0.010250      0.003286         0.003384        0.004125   \n",
       "5        0.015859      0.002999         0.002895        0.004893   \n",
       "10       0.018918      0.004652         0.007189        0.008810   \n",
       "25       0.007878      0.004552         0.000979        0.001251   \n",
       "6        0.014764      0.003057         0.000835        0.001670   \n",
       "15       0.007504      0.003007         0.001065        0.001305   \n",
       "5        0.022462      0.006120         0.002663        0.003871   \n",
       "5        0.045961      0.012108         0.004846        0.006901   \n",
       "16       0.011882      0.005017         0.000807        0.001614   \n",
       "40       0.003429      0.006008         0.003598        0.006944   \n",
       "23       0.006941      0.006119         0.005993        0.004649   \n",
       "51       0.008385      0.006459         0.003650        0.006107   \n",
       "8        0.005971      0.003121         0.006903        0.008044   \n",
       "54       0.008317      0.005373         0.002784        0.002618   \n",
       "43       0.004420      0.006345         0.009169        0.006629   \n",
       "20       0.006192      0.005764         0.001365        0.001829   \n",
       "21       0.009128      0.007687         0.001991        0.002761   \n",
       "46       0.006832      0.007631         0.002907        0.005814   \n",
       "14       0.015773      0.001579         0.000000        0.000000   \n",
       "18       0.010734      0.006858         0.001603        0.003207   \n",
       "10       0.006471      0.004612         0.001423        0.001977   \n",
       "7        0.012817      0.006187         0.003156        0.006312   \n",
       "7        0.010125      0.005416         0.003579        0.003274   \n",
       "8        0.006867      0.007384         0.006304        0.006724   \n",
       "\n",
       "   param_LogisticRegression__C param_LogisticRegression__penalty  \\\n",
       "10                     2.50075                                l2   \n",
       "6                        0.001                              none   \n",
       "10                     2.50075                                l2   \n",
       "15                     2.50075                                l1   \n",
       "5                      2.50075                        elasticnet   \n",
       "21                      5.0005                                l2   \n",
       "11                     2.50075                                l2   \n",
       "5                        0.001                              none   \n",
       "10                       0.001                              none   \n",
       "25                      5.0005                                l1   \n",
       "6                        0.001                              none   \n",
       "15                     2.50075                                l1   \n",
       "5                        0.001                              none   \n",
       "5                        0.001                              none   \n",
       "16                     2.50075                              none   \n",
       "40                        10.0                                l2   \n",
       "23                        10.0                        elasticnet   \n",
       "51                     7.50025                                l2   \n",
       "8                      2.50075                        elasticnet   \n",
       "54                     7.50025                                l2   \n",
       "43                      5.0005                              none   \n",
       "20                      5.0005                                l2   \n",
       "21                        10.0                        elasticnet   \n",
       "46                        10.0                              none   \n",
       "14                     2.50075                                l2   \n",
       "18                     7.50025                        elasticnet   \n",
       "10                     2.50075                                l2   \n",
       "7                        0.001                              none   \n",
       "7                        0.001                              none   \n",
       "8                        0.001                              none   \n",
       "\n",
       "   param_LogisticRegression__solver param_LogisticRegression__tol  \\\n",
       "10                            lbfgs                         0.001   \n",
       "6                         newton-cg                       2.50075   \n",
       "10                              sag                         0.001   \n",
       "15                             saga                         0.001   \n",
       "5                              saga                         0.001   \n",
       "21                            lbfgs                       2.50075   \n",
       "11                        newton-cg                       2.50075   \n",
       "5                               sag                         0.001   \n",
       "10                             saga                         0.001   \n",
       "25                        liblinear                         0.001   \n",
       "6                             lbfgs                       2.50075   \n",
       "15                        liblinear                         0.001   \n",
       "5                             lbfgs                         0.001   \n",
       "5                         newton-cg                         0.001   \n",
       "16                              sag                       2.50075   \n",
       "40                        liblinear                         0.001   \n",
       "23                             saga                       7.50025   \n",
       "51                             saga                       2.50075   \n",
       "8                              saga                       7.50025   \n",
       "54                             saga                          10.0   \n",
       "43                             saga                       7.50025   \n",
       "20                        liblinear                         0.001   \n",
       "21                             saga                       2.50075   \n",
       "46                              sag                       2.50075   \n",
       "14                              sag                          10.0   \n",
       "18                             saga                       7.50025   \n",
       "10                        liblinear                         0.001   \n",
       "7                         newton-cg                        5.0005   \n",
       "7                             lbfgs                        5.0005   \n",
       "8                         newton-cg                       7.50025   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "10  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "6   {'LogisticRegression__C': 0.001, 'LogisticRegr...           1.000000   \n",
       "10  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "15  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "5   {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "21  {'LogisticRegression__C': 5.000500000000001, '...           1.000000   \n",
       "11  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "5   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.952381   \n",
       "10  {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.952381   \n",
       "25  {'LogisticRegression__C': 5.000500000000001, '...           1.000000   \n",
       "6   {'LogisticRegression__C': 0.001, 'LogisticRegr...           1.000000   \n",
       "15  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "5   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.952381   \n",
       "5   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.952381   \n",
       "16  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "40  {'LogisticRegression__C': 10.0, 'LogisticRegre...           0.952381   \n",
       "23  {'LogisticRegression__C': 10.0, 'LogisticRegre...           1.000000   \n",
       "51  {'LogisticRegression__C': 7.50025, 'LogisticRe...           0.857143   \n",
       "8   {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "54  {'LogisticRegression__C': 7.50025, 'LogisticRe...           1.000000   \n",
       "43  {'LogisticRegression__C': 5.000500000000001, '...           0.952381   \n",
       "20  {'LogisticRegression__C': 5.000500000000001, '...           0.952381   \n",
       "21  {'LogisticRegression__C': 10.0, 'LogisticRegre...           0.904762   \n",
       "46  {'LogisticRegression__C': 10.0, 'LogisticRegre...           0.809524   \n",
       "14  {'LogisticRegression__C': 2.50075, 'LogisticRe...           1.000000   \n",
       "18  {'LogisticRegression__C': 7.50025, 'LogisticRe...           0.904762   \n",
       "10  {'LogisticRegression__C': 2.50075, 'LogisticRe...           0.904762   \n",
       "7   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.809524   \n",
       "7   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.904762   \n",
       "8   {'LogisticRegression__C': 0.001, 'LogisticRegr...           0.809524   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "10           0.952381           0.952381           0.952381   \n",
       "6            0.952381           0.952381           0.952381   \n",
       "10           0.952381           0.952381           0.952381   \n",
       "15           0.952381           0.952381           0.952381   \n",
       "5            0.952381           0.952381           0.952381   \n",
       "21           0.952381           0.952381           0.904762   \n",
       "11           0.904762           0.952381           0.952381   \n",
       "5            0.952381           0.904762           0.952381   \n",
       "10           0.952381           0.904762           0.952381   \n",
       "25           0.904762           0.904762           0.952381   \n",
       "6            0.904762           0.952381           0.904762   \n",
       "15           0.904762           0.904762           0.904762   \n",
       "5            0.952381           0.904762           0.952381   \n",
       "5            0.952381           0.904762           0.952381   \n",
       "16           0.904762           0.952381           0.904762   \n",
       "40           0.904762           0.904762           0.904762   \n",
       "23           0.904762           0.904762           0.857143   \n",
       "51           0.952381           1.000000           0.857143   \n",
       "8            0.904762           0.952381           0.809524   \n",
       "54           0.857143           1.000000           0.857143   \n",
       "43           0.952381           0.952381           0.857143   \n",
       "20           0.904762           0.904762           0.857143   \n",
       "21           0.904762           0.952381           0.857143   \n",
       "46           0.904762           0.952381           1.000000   \n",
       "14           0.857143           1.000000           0.809524   \n",
       "18           0.904762           0.952381           0.904762   \n",
       "10           0.904762           0.904762           0.857143   \n",
       "7            0.904762           0.904762           0.857143   \n",
       "7            0.952381           0.809524           0.857143   \n",
       "8            0.857143           0.904762           0.857143   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "10               1.00         0.971429        0.023328                1   \n",
       "6                1.00         0.971429        0.023328                1   \n",
       "10               1.00         0.971429        0.023328                1   \n",
       "15               1.00         0.971429        0.023328                1   \n",
       "5                1.00         0.971429        0.023328                1   \n",
       "21               0.95         0.951905        0.030132                5   \n",
       "11               0.95         0.951905        0.030132               12   \n",
       "5                0.95         0.942381        0.018832                5   \n",
       "10               0.95         0.942381        0.018832                9   \n",
       "25               0.95         0.942381        0.035520                1   \n",
       "6                0.95         0.942381        0.035520                8   \n",
       "15               0.95         0.932857        0.037868                4   \n",
       "5                0.90         0.932381        0.024541               14   \n",
       "5                0.90         0.932381        0.024541               14   \n",
       "16               0.90         0.932381        0.038850               10   \n",
       "40               0.95         0.923333        0.022758                5   \n",
       "23               0.95         0.923333        0.048291                5   \n",
       "51               0.95         0.923333        0.056912               14   \n",
       "8                0.95         0.923333        0.064390                5   \n",
       "54               0.90         0.922857        0.064902               15   \n",
       "43               0.90         0.922857        0.038615               16   \n",
       "20               0.95         0.913810        0.035135                6   \n",
       "21               0.95         0.913810        0.035135                7   \n",
       "46               0.90         0.913333        0.063346               11   \n",
       "14               0.90         0.913333        0.076333               11   \n",
       "18               0.90         0.913333        0.019611                8   \n",
       "10               0.95         0.904286        0.029370                8   \n",
       "7                0.95         0.885238        0.047913               19   \n",
       "7                0.90         0.884762        0.048225               19   \n",
       "8                0.80         0.845714        0.037808               28   \n",
       "\n",
       "   param_LogisticRegression__l1_ratio  \n",
       "10                                NaN  \n",
       "6                                 NaN  \n",
       "10                                NaN  \n",
       "15                                NaN  \n",
       "5                               0.001  \n",
       "21                                NaN  \n",
       "11                                NaN  \n",
       "5                                 NaN  \n",
       "10                                NaN  \n",
       "25                                NaN  \n",
       "6                                 NaN  \n",
       "15                                NaN  \n",
       "5                                 NaN  \n",
       "5                                 NaN  \n",
       "16                                NaN  \n",
       "40                                NaN  \n",
       "23                              0.001  \n",
       "51                                NaN  \n",
       "8                               0.001  \n",
       "54                                NaN  \n",
       "43                                NaN  \n",
       "20                                NaN  \n",
       "21                              0.001  \n",
       "46                                NaN  \n",
       "14                                NaN  \n",
       "18                              0.001  \n",
       "10                                NaN  \n",
       "7                                 NaN  \n",
       "7                                 NaN  \n",
       "8                                 NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best=pd.concat([df_1.head(),df_2.head(),df_3.head(),df_4.head(),df_5.head(),df_6.head()])\n",
    "best1=best.sort_values(by=['mean_test_score', 'std_test_score'], ascending=[False, True])\n",
    "best1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1835790917.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [28]\u001b[1;36m\u001b[0m\n\u001b[1;33m    prin gax\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "prin gax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'LogisticRegression__C': [2.50075], 'LogisticRegression__penalty': ['l2'], 'LogisticRegression__solver': ['lbfgs'], 'LogisticRegression__tol': [0.001]},\n",
       "       {'LogisticRegression__C': [0.001], 'LogisticRegression__penalty': ['none'], 'LogisticRegression__solver': ['newton-cg'], 'LogisticRegression__tol': [2.50075]},\n",
       "       {'LogisticRegression__C': [2.50075], 'LogisticRegression__penalty': ['l2'], 'LogisticRegression__solver': ['sag'], 'LogisticRegression__tol': [0.001]},\n",
       "       {'LogisticRegression__C': [2.50075], 'LogisticRegression__penalty': ['l1'], 'LogisticRegression__solver': ['saga'], 'LogisticRegression__tol': [0.001]},\n",
       "       {'LogisticRegression__C': [2.50075], 'LogisticRegression__l1_ratio': [0.001], 'LogisticRegression__penalty': ['elasticnet'], 'LogisticRegression__solver': ['saga'], 'LogisticRegression__tol': [0.001]},\n",
       "       {'LogisticRegression__C': [5.000500000000001], 'LogisticRegression__penalty': ['l2'], 'LogisticRegression__solver': ['lbfgs'], 'LogisticRegression__tol': [2.50075]},\n",
       "       {'LogisticRegression__C': [2.50075], 'LogisticRegression__penalty': ['l2'], 'LogisticRegression__solver': ['newton-cg'], 'LogisticRegression__tol': [2.50075]},\n",
       "       {'LogisticRegression__C': [0.001], 'LogisticRegression__penalty': ['none'], 'LogisticRegression__solver': ['sag'], 'LogisticRegression__tol': [0.001]},\n",
       "       {'LogisticRegression__C': [0.001], 'LogisticRegression__penalty': ['none'], 'LogisticRegression__solver': ['saga'], 'LogisticRegression__tol': [0.001]},\n",
       "       {'LogisticRegression__C': [5.000500000000001], 'LogisticRegression__penalty': ['l1'], 'LogisticRegression__solver': ['liblinear'], 'LogisticRegression__tol': [0.001]}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= ambil_best(best,10)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652394146977343649\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    experiment_id = mlflow.create_experiment(\n",
    "        name=\"project_logistic_iris_new\",\n",
    "        tags={\"env\": \"dev\", \"version\": \"1.0.0\"},\n",
    "    )\n",
    "\n",
    "    print(experiment_id)\n",
    "    \n",
    "\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"log___\"\n",
    "increment_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-396cf07c-75a8-4007-8362-7d546168a611 {color: black;background-color: white;}#sk-396cf07c-75a8-4007-8362-7d546168a611 pre{padding: 0;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-toggleable {background-color: white;}#sk-396cf07c-75a8-4007-8362-7d546168a611 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-396cf07c-75a8-4007-8362-7d546168a611 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-396cf07c-75a8-4007-8362-7d546168a611 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-396cf07c-75a8-4007-8362-7d546168a611 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-396cf07c-75a8-4007-8362-7d546168a611 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-396cf07c-75a8-4007-8362-7d546168a611 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-estimator:hover {background-color: #d4ebff;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-item {z-index: 1;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-parallel-item:only-child::after {width: 0;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-396cf07c-75a8-4007-8362-7d546168a611 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-396cf07c-75a8-4007-8362-7d546168a611\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                (&#x27;LogisticRegression&#x27;, LogisticRegression(max_iter=10000))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b3a07adf-f2b6-481c-b742-c9245044cf01\" type=\"checkbox\" ><label for=\"b3a07adf-f2b6-481c-b742-c9245044cf01\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;StandardScaler&#x27;, StandardScaler()),\n",
       "                (&#x27;LogisticRegression&#x27;, LogisticRegression(max_iter=10000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8aef02fd-ac97-46d2-a1e8-5b48624c7fc5\" type=\"checkbox\" ><label for=\"8aef02fd-ac97-46d2-a1e8-5b48624c7fc5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1abbe109-3530-4815-a736-50b7878640ca\" type=\"checkbox\" ><label for=\"1abbe109-3530-4815-a736-50b7878640ca\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('StandardScaler', StandardScaler()),\n",
       "                ('LogisticRegression', LogisticRegression(max_iter=10000))])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 2cf29388fd1942509f33c7dc2539d8b3\n",
      "run_id: 3f156b0081ab4250913318346e23574b\n",
      "run_id: 4090b31e592743ce8d66ba56b3e820d4\n",
      "run_id: 86cc3db5bba1442a89e1e6fddc200d4d\n",
      "run_id: f5e3990be37e45ffb1224fb4177dc5be\n",
      "run_id: 0bceeadfc7654420826ae5a03975a06c\n",
      "run_id: 7ec89b3781d64416a6b9cf6420a05eb1\n",
      "run_id: 8683f90946234ae0b39f0fab5694fc8c\n",
      "run_id: 0838f7685d3f4e528c49aa81f6244125\n",
      "run_id: 2aa8acf1afa949b882b2778f60667240\n",
      "selesai\n"
     ]
    }
   ],
   "source": [
    "\n",
    "increment_number=input_mlflow(data,increment_number,X_train, y_train,pipeline,run_name,experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================| model 1 |==========================================\n",
      "Classification Report for model _1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        13\n",
      "  versicolor       1.00      0.93      0.97        15\n",
      "   virginica       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Confusion Matrix for model _1:\n",
      " [[13  0  0]\n",
      " [ 0 14  1]\n",
      " [ 0  0 17]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================| model 2 |==========================================\n",
      "Classification Report for model _3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        13\n",
      "  versicolor       1.00      1.00      1.00        15\n",
      "   virginica       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "Confusion Matrix for model _3:\n",
      " [[13  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 17]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================| model 3 |==========================================\n",
      "Classification Report for model _4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        13\n",
      "  versicolor       0.93      0.93      0.93        15\n",
      "   virginica       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "Confusion Matrix for model _4:\n",
      " [[13  0  0]\n",
      " [ 0 14  1]\n",
      " [ 0  1 16]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_paths = [\n",
    "  \n",
    "    'mlruns/652394146977343649/2cf29388fd1942509f33c7dc2539d8b3/artifacts/grid_search__1',\n",
    "    'mlruns/652394146977343649/4090b31e592743ce8d66ba56b3e820d4/artifacts/grid_search__3',\n",
    "    'mlruns/652394146977343649/86cc3db5bba1442a89e1e6fddc200d4d/artifacts/grid_search__4',\n",
    "    \n",
    "    \n",
    "    ]\n",
    "\n",
    "test(model_paths,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
